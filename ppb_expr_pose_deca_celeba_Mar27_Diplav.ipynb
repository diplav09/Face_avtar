{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbcJXGBnFmEU",
        "outputId": "465a61ec-e031-40de-c744-0e92c2acaf2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) # My Drive\n",
        "# Change to your local path if needed\n",
        "import os\n",
        "path = '/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/DECA/DECA'\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R-ic9Seq6PlR",
        "outputId": "aaa6ce3c-2dd2-4c6f-fd40-07e9ee263032"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/DECA/DECA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "testpath = '/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/FaceForensics/videos/original_sequences/youtube/raw/videos'\n",
        "files = glob(testpath + '/*.mp4')"
      ],
      "metadata": {
        "id": "C1f7CuOGBIJF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ErQlMwd7Cc5H",
        "outputId": "9f9add9c-005f-45c0-d9c5-8e97ac4ff805"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/FaceForensics/videos/original_sequences/youtube/raw/videos/585.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5CWCn9OdI7k",
        "outputId": "690d7227-6980-4342-d6ce-90aee1443b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar 29 16:12:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M_LTpjumiqLC"
      },
      "outputs": [],
      "source": [
        "# !cp -r ./../../PPB_all /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDC_JjFCRoOX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAdXPYYyYwBX",
        "outputId": "e076cebd-2f93-4312-ef7f-a93ee73c2e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/bupt_balanced_480.zip\n",
            "   creating: /content/bupt_balanced_480/\n",
            "  inflating: /content/bupt_balanced_480/Indianm0jl05tmc_1.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0546q9000042_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm059_rzq2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm027b3l9000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0h_j5wm112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0clcqv102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nccxf6000077_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04nxfq11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02q9tgl000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm023vbq62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0d2zzh62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01lpl7c11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05f60dn000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02w5zsd62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0bw9nr2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm06vf2q000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01vmgq962-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm010wb7ld000029_00@zh-Hant.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0bh9h0q000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0h0b3n000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm05p1nwh000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm021c5y102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0gyt28g62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03y4zc000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0b0mpt9-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm047rdxn000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0b_tc7102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0gmkt9h000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03f0rhs102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0c3ydbd000063_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm07vcky2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm028q9462-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05xpj2h000037_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm07s52yr102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06thb562-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03hzyhf62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05myrq262-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0bkp1p2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0b8_1t000131_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm05b1cvv000025_04@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0446w551-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05ylh84000038_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02qrd05000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm027bbh4000042_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0k9flsd000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0ndbcdv000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm097vtn89-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03gxqvr000002_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0bwhs2n000064_08@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm050611000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm048_p112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0qd51fy000007_01@it.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0489n011-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01wk5_r42-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0czdtxs000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0f4pfm000016_01@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0_s4fmg000038_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03c0667000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06fd7h2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0hr0_h_112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0bstqx000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05w88j2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0k8nqt4000002_00@uk.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0c1b4m62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01qk7ml2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm042wt622-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm026p8ld62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm05c4f4p000049_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02lh__62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02f5ky72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01w1_r921-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03kjtk112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0474v711-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm07ydp3000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0jx_j5106-FaceId-4_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0jywhv000049_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0r4mswh000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0hzs67y000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0h3dxd000002_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0gj8d5t102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gg9k6t000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0j7jlf4000131_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm09x7gw000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0h0kjd000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06dx0w11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05wt4hf000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm02rb72m000027_02@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0bm0md000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02q63zv2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gc5n29000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0glrbss000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm07dc1r000016_01@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm049q0m102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0x31dp22-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0264_ks62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0kjwq88000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02796vm2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03j1kg11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03hzg5162-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03gsj5062-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm08by2k000038_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02pkvpm2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0g5p_sp000032_00@zh.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm017hys000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm068rqt11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm027_7cq2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0fppc8h000027_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm080fgy962-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0dfv8c89-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm07d66c2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm04yh278000016_01@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm09v4gj7-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0jzxzv000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02czc82-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0b8zw6000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm01v9ttm000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02rzt92-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0c6b_4102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0bkg5f000056_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm011v61_7000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0521q39102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0y6469_000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0fzpqn102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0jkzzhv000014_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0cmcmqz000063_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0bbybnw000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm09v93hd000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01w01y762-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06k7hx62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01l8wwt2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0fccnv11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0hzmq1n11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0y8d6ps000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm04zz91_000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0279bh9000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0k2kf1n000034_06@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0jkzwxr000049_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0hgmygh000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm064flw11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0gxs2472-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0114lz13000131_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03j62w2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nbhd3r000015_06@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm026129x000021_00@zh-Hant.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm058tt162-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm04xwcq000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm026nhh011-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm051vfw9000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0gy1vk062-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0dykxx000005_01@zh.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm06_wyw0000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm09rvsp8000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0wq769r000057_01@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm027f3862-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02q4lkl62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gc408h000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm05sx1jy62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06hm4z2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02m6z342-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03hh97p000027_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nbdn0k000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03bmvc102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0bb8mbv62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0g9mf2t000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0gc0qkw000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0h_fjsl72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm07s42b811-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0bwlfyw2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0pd39mz000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0j_mrg000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm09rvw6p000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02g79h000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0752f472-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0cgbjf000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0h536402-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03h5mpk000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03h0lt7000006_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04f50p62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0j_c10000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0ryw83f62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01rrxr102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm03cpk_62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0bqccl2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gjc9qd000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0g5pzv3000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0351m72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm02qpydz000002_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm05j76g2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0c_h2t62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0kbj3pn000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0czbn9m000014_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03hmr57000014_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm034qpf2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0gd1w72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm065y7bn000042_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm043ly7d62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0264vdw000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0181ph11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0fmg2c102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01nxcdf62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm045cq62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0k35y5000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm047r13s72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm019qkl11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0bdpvw62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01p27qd102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm026y48_000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0b74797000021_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03_3bt2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm045fr61-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm04sjf372-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0j9kzbz000049_02@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0519ws1000125_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0268kcv000048_00@vi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0h1d1s9000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0n9bdhy000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm017vkk102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm07b2lv102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gpb_162-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0bllkq62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01wpj5721-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm08mpfz2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0jt4gdh000006_00@ru.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03ryks11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm047mwj62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0j10xr0000027_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0wys17b000016_01@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0j621fc000006_00@ru.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0g870q102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0464x8l000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0l60g1t000077_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm02ry76f000003_00@hu.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02r_7tn102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm027_dnb112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0hh8vjk000042_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm080ln5b000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm08k00r102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0dx8b_62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05x2prg000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0404ys4000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05993q2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0gmbrg4000002_01@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0j7mqjz000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02631542-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0r5wwgn000063_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03hgw55000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm010lymr7000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0272rxg000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gbvnqy000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0dshxd62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm04ygzsz000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm026yt4f000002_01@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm025v_zp62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm076x1k5000006_00@ru.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03k4fv112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm021df062-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02rc_5411-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0dr_dbf62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm074z1z22-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nhcsfg000011_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nfzcgv000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm04cpqn62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01vgyy72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0j3dvy1000077_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0263l77000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0n545_6102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01tcf72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0hq1_yz000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0803fx62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm018qz3112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0bg8tx000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm04n256g2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0269ps9000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm021yd177-FaceId-1_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0flqrc000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm027y3bk000046_03@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0b6p2grc_1.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0cmbb6y000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm071dr2000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01m4rnj102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm097llw62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0hm3562-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm015z4j62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05zsw8_000042_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03z0rl000037_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0_vpy3l000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03c8fdb000046_03@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nhfwq4000028_03@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm05t0q_m2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05dbbs84-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03d9fgw000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02vx9_62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0gtvszp62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0112wzmr000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0125p804000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05myty000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm09v9rrn000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0yhjkvw000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm010d_94v000016_01@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm05sxqch000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm03c22fz62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm073dnn62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02qmvj262-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm07kh0nw2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm07k7xhj000038_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0_hcm66000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0ngwbln000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01nbzpm62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm055k79k000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0crdw2w72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm080c39r000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0gl7xv42-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm04jmydp000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm08m90x56-FaceId-9_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0453vm2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0bp45d000002_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm09g6lvd62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0600t862-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0q2c239-FaceId-1_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02502p2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm08d84562-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03hmvs3000014_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02q9ytg000000_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02q82vd000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0579cyd000042_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm011cnb04000017_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0j9lcg3000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm043mhm71-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm04_j8y000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0fwq3562-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm027wd3d000063_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm05zld8n000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02w3_js72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0640wwr62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0pcm4rb000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0b03ks000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm03f3bqb84-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01v26y362-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03cx67r000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05g22z2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0zbg_8m000022_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0gykqj62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm025zry62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0ff1d6102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm08v6hv2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0dsb23q000146_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0283sq0000014_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm075mnc7-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0cyly062-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01gkbj122-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01wn1g102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nhh2tf000037_01@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm04g6dhj000008_00@de.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0n52kr2000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03sysz62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01cd7862-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05bmks62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04crw62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0fpgpt962-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0bk82272-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0b73zkr000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0hglgnx000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01m_mxk62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0jww8jz2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm07kmyl000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm01yjnz000000_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02w2_td102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0bbzg9f000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm09f0bj62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01vyz3p62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0ff9h7000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm04bl4362-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm07s7xcp000002_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01_qht11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0812mc21-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05c453q62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04q3q18102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0h6hjg000003_00@ko.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0l3yzq1000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm01ws13v000033_02@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0fq2lzw000014_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02x91d962-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02wl59l22-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm03j1sg511-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04y2g489-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02rb0d2000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm069zf162-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01d_m_62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm010f8k2z000038_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm07ljhf102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01gdx432-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gx1wwx62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0d7rky000006_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04b15t52-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm052_bl11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm01yjm0000042_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0h7l7k2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01n3_lp89-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm04hg2p62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0l402z6000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0gj7bw0000058_00@zh-Hant.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm04_zc_000006_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm04c9nq112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04yd27l52-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0bwgsv_000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm02z4ghy000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0wzzfmw000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05jkgv31-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0b294l000019_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0r8lrr22-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01wbx8g102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm05218362-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0nhy9p0000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0bd8vv2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm07s5dd_000001_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02r2jx_62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm040_t62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm015pr162-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm03c6x11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0nd5gkt000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm05575j52-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0h4rh2000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0fhj0z000019_00@hi.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01mg32m62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0kryc8000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0dsf2b72-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0h36c8000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0cjd7x62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0bmc_h366-FaceId-4_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0h80hlg000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm027cw4c000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0d5hv2-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm02ppvr462-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0dqjhr62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06lv3r62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05x5068000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0804v02-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm07m9t_000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02w7fxy000033_02@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0f27lm62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm03qmx1w000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0ggbpq5000012_02@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm05mq46000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0g571fy122-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0ccyg7000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0g5qgv11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0gh7f4z62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm09vd9_22-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm01p941102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0k8k_zm000013_00@zh.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0t52z4j000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0gk_hnn62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm02r8032000005_01@zh.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0gj3jr_000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0dd2kh000014_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0h7lz7p102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm04mxttm62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm04grrr1102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0bxr_82-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0knwgqr62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm06dtvp62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02qnh39000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0d6nkw62-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm05b1zq7000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm025xbrw000008_00@it.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0214xp102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0113jjnl000019_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm0gkc4m5000063_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm02716sb000000_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm04y93xb000016_01@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0b0g5k11-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm06qwtx112-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm01kbx27-FaceId-1_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm02qjhp7102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03ql10q000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Indianm01tx3qm000077_00@en.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Africanm0k0tfvx64-FaceId-1_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Caucasianm0gq5cn102-FaceId-0_align.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm0ngw9mr000019_00@ja.jpg  \n",
            "  inflating: /content/bupt_balanced_480/Asianm03cmwzv000059_01@ja.jpg  \n"
          ]
        }
      ],
      "source": [
        "!cp ./../bupt_balanced_480.zip -d /content/\n",
        "!unzip /content/bupt_balanced_480.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UQ5nrZRUCuap"
      },
      "outputs": [],
      "source": [
        "# !ls /content/PPB_dataset/F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O1pJFecFpQQ",
        "outputId": "ac063fdd-e85e-4406-f2a3-282a027bfdcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
            "Collecting chumpy>=0.69\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.15 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n",
            "Collecting PyYAML>=5.1.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 15.1 MB/s \n",
            "\u001b[?25hCollecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 19 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 61.0 MB/s \n",
            "\u001b[?25hCollecting face-alignment\n",
            "  Downloading face_alignment-1.3.5.tar.gz (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0->-r requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from chumpy>=0.69->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15->-r requirements.txt (line 6)) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15->-r requirements.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.15->-r requirements.txt (line 6)) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->-r requirements.txt (line 6)) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.15->-r requirements.txt (line 6)) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from face-alignment->-r requirements.txt (line 12)) (4.63.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from face-alignment->-r requirements.txt (line 12)) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment->-r requirements.txt (line 12)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->face-alignment->-r requirements.txt (line 12)) (0.34.0)\n",
            "Building wheels for collected packages: chumpy, face-alignment\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58285 sha256=d2179f7be58f1241b7086f0d2c4734df12f9bdf46f607a4da352e14176d13f28\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/68/de/5e0c5d77e573e8c150e69e07a25035e6b6a04952d6e1814dbc\n",
            "  Building wheel for face-alignment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-alignment: filename=face_alignment-1.3.5-py2.py3-none-any.whl size=28241 sha256=fa19a88f92ff0af85237c8d7100f15c80c3f19a652fbba0813081110525d62cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/ba/4d/2d368f55e5f929f9472da59e356fbdf1483f885de80a5bc620\n",
            "Successfully built chumpy face-alignment\n",
            "Installing collected packages: torch, torchvision, PyYAML, face-alignment, chumpy\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 chumpy-0.70 face-alignment-1.3.5 torch-1.6.0 torchvision-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiKGa-6fF1Wz",
        "outputId": "7299ad3d-4409-41cb-f8ce-0208f921e23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorch3d.git\n",
            "  Cloning https://github.com/facebookresearch/pytorch3d.git to /tmp/pip-req-build-6kj7dj3z\n",
            "  Running command git clone -q https://github.com/facebookresearch/pytorch3d.git /tmp/pip-req-build-6kj7dj3z\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20220305.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.1) (1.21.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.1) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.1) (4.63.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.1) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.1) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d==0.6.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: pytorch3d, fvcore\n",
            "  Building wheel for pytorch3d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch3d: filename=pytorch3d-0.6.1-cp37-cp37m-linux_x86_64.whl size=24932653 sha256=001ccd6c56f019ef02710652b7a238c645ed97b84a59cb88ba4f59cfaa84b950\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i8a5fwao/wheels/db/2f/07/b84807ee4c9ffc917b90b716977d7fea8f9e841f6173150600\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220305-py3-none-any.whl size=61214 sha256=1ce2c6f5d43c0991fcbfb888c05494914f9f1eced10305f38560a8719bf0faae\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b7/6e/43b1693d06fac3633af48db68557513b0a37ab38b0a8b798f9\n",
            "Successfully built pytorch3d fvcore\n",
            "Installing collected packages: portalocker, yacs, iopath, fvcore, pytorch3d\n",
            "\u001b[31mERROR: For req: pytorch3d==0.6.1. Invalid script entry point: <ExportEntry pytorch3d_implicitron_runner = projects.implicitron_trainer.experiment:None []> - A callable suffix is required. Cf https://packaging.python.org/specifications/entry-points/#use-for-scripts for more information.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/pytorch3d.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gifUD7h1PIe-"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WEUJ4JtbF4FQ"
      },
      "outputs": [],
      "source": [
        "import time, os, sys, math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from time import time\n",
        "from scipy.io import savemat\n",
        "import argparse\n",
        "import imageio\n",
        "from skimage.transform import rescale\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py \n",
        "from pathlib import Path\n",
        "import pandas as pd \n",
        "\n",
        "# sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))\n",
        "from decalib.deca import DECA\n",
        "from decalib.datasets import datasets \n",
        "from decalib.utils import util\n",
        "from decalib.utils.rotation_converter import batch_euler2axis, deg2rad\n",
        "from decalib.utils.config import cfg as deca_cfg\n",
        "\n",
        "import os, sys\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "from time import time\n",
        "from skimage.io import imread\n",
        "import cv2\n",
        "import pickle\n",
        "sys.path.insert(0, os.path.join(os.getcwd(), 'decalib'))\n",
        "from utils.renderer import SRenderY_modified\n",
        "# from utils.renderer import SRenderY\n",
        "from models.encoders import ResnetEncoder\n",
        "from models.FLAME import FLAME, FLAMETex\n",
        "from models.decoders import Generator\n",
        "from utils import util\n",
        "from utils.rotation_converter import batch_euler2axis\n",
        "from datasets import datasets_video\n",
        "from utils.config import cfg\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "import scipy.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as utils\n",
        "from torch.utils.data import Dataset, TensorDataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import argparse\n",
        "from matplotlib import cm\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXY3rnQ3dn-k"
      },
      "source": [
        "# Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kSsQBZj_doFa"
      },
      "outputs": [],
      "source": [
        "def show_img(img):\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "def show_img_final(img, savename):\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.savefig(savename, bbox_inches='tight')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x4EOXqaOaFK"
      },
      "source": [
        "# DECA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vGCCGGaog-vH"
      },
      "outputs": [],
      "source": [
        "class DECA(object):\n",
        "    def __init__(self, config=None, device='cuda'):\n",
        "        if config is None:\n",
        "            self.cfg = cfg\n",
        "        else:\n",
        "            self.cfg = config\n",
        "        self.device = device\n",
        "        self.image_size = self.cfg.dataset.image_size\n",
        "        self.uv_size = self.cfg.model.uv_size\n",
        "\n",
        "        self._create_model(self.cfg.model)\n",
        "        self._setup_renderer(self.cfg.model)\n",
        "\n",
        "    def _setup_renderer(self, model_cfg):\n",
        "        # self.render = SRenderY(self.image_size, obj_filename=model_cfg.topology_path, uv_size=model_cfg.uv_size).to(self.device)\n",
        "        self.render = SRenderY_modified(self.image_size, obj_filename=model_cfg.topology_path, uv_size=model_cfg.uv_size).to(self.device)\n",
        "        # face mask for rendering details\n",
        "        mask = imread(model_cfg.face_eye_mask_path).astype(np.float32)/255.; mask = torch.from_numpy(mask[:,:,0])[None,None,:,:].contiguous()\n",
        "        self.uv_face_eye_mask = F.interpolate(mask, [model_cfg.uv_size, model_cfg.uv_size]).to(self.device)\n",
        "        mask = imread(model_cfg.face_mask_path).astype(np.float32)/255.; mask = torch.from_numpy(mask[:,:,0])[None,None,:,:].contiguous()\n",
        "        self.uv_face_mask = F.interpolate(mask, [model_cfg.uv_size, model_cfg.uv_size]).to(self.device)\n",
        "        # displacement correction\n",
        "        fixed_dis = np.load(model_cfg.fixed_displacement_path)\n",
        "        self.fixed_uv_dis = torch.tensor(fixed_dis).float().to(self.device)\n",
        "        # mean texture\n",
        "        mean_texture = imread(model_cfg.mean_tex_path).astype(np.float32)/255.; mean_texture = torch.from_numpy(mean_texture.transpose(2,0,1))[None,:,:,:].contiguous()\n",
        "        self.mean_texture = F.interpolate(mean_texture, [model_cfg.uv_size, model_cfg.uv_size]).to(self.device)\n",
        "        # dense mesh template, for save detail mesh\n",
        "        self.dense_template = np.load(model_cfg.dense_template_path, allow_pickle=True, encoding='latin1').item()\n",
        "\n",
        "    def _create_model(self, model_cfg):\n",
        "        # set up parameters\n",
        "        self.n_param = model_cfg.n_shape+model_cfg.n_tex+model_cfg.n_exp+model_cfg.n_pose+model_cfg.n_cam+model_cfg.n_light\n",
        "        self.n_detail = model_cfg.n_detail\n",
        "        self.n_cond = model_cfg.n_exp + 3 # exp + jaw pose\n",
        "        self.num_list = [model_cfg.n_shape, model_cfg.n_tex, model_cfg.n_exp, model_cfg.n_pose, model_cfg.n_cam, model_cfg.n_light]\n",
        "        self.param_dict = {i:model_cfg.get('n_' + i) for i in model_cfg.param_list}\n",
        "\n",
        "        # encoders\n",
        "        self.E_flame = ResnetEncoder(outsize=self.n_param).to(self.device) \n",
        "        self.E_detail = ResnetEncoder(outsize=self.n_detail).to(self.device)\n",
        "        # decoders\n",
        "        self.flame = FLAME(model_cfg).to(self.device)\n",
        "        if model_cfg.use_tex:\n",
        "            self.flametex = FLAMETex(model_cfg).to(self.device)\n",
        "        self.D_detail = Generator(latent_dim=self.n_detail+self.n_cond, out_channels=1, out_scale=model_cfg.max_z, sample_mode = 'bilinear').to(self.device)\n",
        "        # resume model\n",
        "        model_path = self.cfg.pretrained_modelpath\n",
        "        if os.path.exists(model_path):\n",
        "            print(f'trained model found. load {model_path}')\n",
        "            checkpoint = torch.load(model_path)\n",
        "            self.checkpoint = checkpoint\n",
        "            util.copy_state_dict(self.E_flame.state_dict(), checkpoint['E_flame'])\n",
        "            util.copy_state_dict(self.E_detail.state_dict(), checkpoint['E_detail'])\n",
        "            util.copy_state_dict(self.D_detail.state_dict(), checkpoint['D_detail'])\n",
        "        else:\n",
        "            print(f'please check model path: {model_path}')\n",
        "            exit()\n",
        "        # eval mode\n",
        "        self.E_flame.eval()\n",
        "        self.E_detail.eval()\n",
        "        self.D_detail.eval()\n",
        "\n",
        "    def decompose_code(self, code, num_dict):\n",
        "        ''' Convert a flattened parameter vector to a dictionary of parameters\n",
        "        code_dict.keys() = ['shape', 'tex', 'exp', 'pose', 'cam', 'light']\n",
        "        '''\n",
        "        code_dict = {}\n",
        "        start = 0\n",
        "        for key in num_dict:\n",
        "            end = start+int(num_dict[key])\n",
        "            code_dict[key] = code[:, start:end]\n",
        "            start = end\n",
        "            if key == 'light':\n",
        "                code_dict[key] = code_dict[key].reshape(code_dict[key].shape[0], 9, 3)\n",
        "        return code_dict\n",
        "\n",
        "    def displacement2normal(self, uv_z, coarse_verts, coarse_normals):\n",
        "        ''' Convert displacement map into detail normal map\n",
        "        '''\n",
        "        batch_size = uv_z.shape[0]\n",
        "        uv_coarse_vertices = self.render.world2uv(coarse_verts).detach()\n",
        "        uv_coarse_normals = self.render.world2uv(coarse_normals).detach()\n",
        "    \n",
        "        uv_z = uv_z*self.uv_face_eye_mask\n",
        "        uv_detail_vertices = uv_coarse_vertices + uv_z*uv_coarse_normals + self.fixed_uv_dis[None,None,:,:]*uv_coarse_normals.detach()\n",
        "        dense_vertices = uv_detail_vertices.permute(0,2,3,1).reshape([batch_size, -1, 3])\n",
        "        uv_detail_normals = util.vertex_normals(dense_vertices, self.render.dense_faces.expand(batch_size, -1, -1))\n",
        "        uv_detail_normals = uv_detail_normals.reshape([batch_size, uv_coarse_vertices.shape[2], uv_coarse_vertices.shape[3], 3]).permute(0,3,1,2)\n",
        "        return uv_detail_normals\n",
        "\n",
        "    def displacement2vertex(self, uv_z, coarse_verts, coarse_normals):\n",
        "        ''' Convert displacement map into detail vertices\n",
        "        '''\n",
        "        batch_size = uv_z.shape[0]\n",
        "        uv_coarse_vertices = self.render.world2uv(coarse_verts).detach()\n",
        "        uv_coarse_normals = self.render.world2uv(coarse_normals).detach()\n",
        "    \n",
        "        uv_z = uv_z*self.uv_face_eye_mask\n",
        "        uv_detail_vertices = uv_coarse_vertices + uv_z*uv_coarse_normals + self.fixed_uv_dis[None,None,:,:]*uv_coarse_normals.detach()\n",
        "        dense_vertices = uv_detail_vertices.permute(0,2,3,1).reshape([batch_size, -1, 3])\n",
        "        # uv_detail_normals = util.vertex_normals(dense_vertices, self.render.dense_faces.expand(batch_size, -1, -1))\n",
        "        # uv_detail_normals = uv_detail_normals.reshape([batch_size, uv_coarse_vertices.shape[2], uv_coarse_vertices.shape[3], 3]).permute(0,3,1,2)\n",
        "        detail_faces =  self.render.dense_faces\n",
        "        return dense_vertices, detail_faces\n",
        "\n",
        "    def visofp(self, normals):\n",
        "        ''' visibility of keypoints, based on the normal direction\n",
        "        '''\n",
        "        normals68 = self.flame.seletec_3d68(normals)\n",
        "        vis68 = (normals68[:,:,2:] < 0.1).float()\n",
        "        return vis68\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "        parameters = self.E_flame(images)\n",
        "        detailcode = self.E_detail(images)\n",
        "        codedict = self.decompose_code(parameters, self.param_dict)\n",
        "        codedict['detail'] = detailcode\n",
        "        codedict['images'] = images\n",
        "        return codedict\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def decode(self, codedict):\n",
        "        images = codedict['images']\n",
        "        batch_size = images.shape[0]\n",
        "        \n",
        "        ## decode\n",
        "        verts, landmarks2d, landmarks3d = self.flame(shape_params=codedict['shape'], expression_params=codedict['exp'], pose_params=codedict['pose'])\n",
        "        uv_z = self.D_detail(torch.cat([codedict['pose'][:,3:], codedict['exp'], codedict['detail']], dim=1))\n",
        "        if self.cfg.model.use_tex:\n",
        "            albedo = self.flametex(codedict['tex'])\n",
        "        else:\n",
        "            albedo = torch.zeros([batch_size, 3, self.uv_size, self.uv_size], device=images.device) \n",
        "        ## projection\n",
        "        landmarks2d = util.batch_orth_proj(landmarks2d, codedict['cam'])[:,:,:2]; landmarks2d[:,:,1:] = -landmarks2d[:,:,1:]; landmarks2d = landmarks2d*self.image_size/2 + self.image_size/2\n",
        "        landmarks3d = util.batch_orth_proj(landmarks3d, codedict['cam']); landmarks3d[:,:,1:] = -landmarks3d[:,:,1:]; landmarks3d = landmarks3d*self.image_size/2 + self.image_size/2\n",
        "        trans_verts = util.batch_orth_proj(verts, codedict['cam']); trans_verts[:,:,1:] = -trans_verts[:,:,1:]\n",
        "        \n",
        "        ## rendering\n",
        "        ops = self.render(verts, trans_verts, albedo, codedict['light'])\n",
        "        uv_detail_normals = self.displacement2normal(uv_z, verts, ops['normals'])\n",
        "        uv_shading = self.render.add_SHlight(uv_detail_normals, codedict['light'])\n",
        "        uv_texture = albedo*uv_shading\n",
        "\n",
        "        landmarks3d_vis = self.visofp(ops['transformed_normals'])\n",
        "        landmarks3d = torch.cat([landmarks3d, landmarks3d_vis], dim=2)\n",
        "\n",
        "        ## render shape\n",
        "        shape_images = self.render.render_shape(verts, trans_verts, images=ops['albedo_images'], lights=codedict['light'])\n",
        "        # shape_images = self.render.render_shape(verts, trans_verts)\n",
        "\n",
        "        detail_normal_images = F.grid_sample(uv_detail_normals, ops['grid'], align_corners=False)*ops['alpha_images']\n",
        "        # shape_detail_images = self.render.render_shape(verts, trans_verts, detail_normal_images=detail_normal_images)\n",
        "        shape_detail_images = self.render.render_shape(verts, trans_verts, images=ops['albedo_images'], detail_normal_images=detail_normal_images, lights=codedict['light'])\n",
        "        \n",
        "        ## extract texture\n",
        "        ## TODO: current resolution 256x256, support higher resolution, and add visibility\n",
        "        uv_pverts = self.render.world2uv(trans_verts)\n",
        "        uv_gt = F.grid_sample(images, uv_pverts.permute(0,2,3,1)[:,:,:,:2], mode='bilinear')\n",
        "        if self.cfg.model.use_tex:\n",
        "            ## TODO: poisson blending should give better-looking results\n",
        "            uv_texture_gt = uv_gt[:,:3,:,:]*self.uv_face_eye_mask + (uv_texture[:,:3,:,:]*(1-self.uv_face_eye_mask)*0.7)\n",
        "        else:\n",
        "            uv_texture_gt = uv_gt[:,:3,:,:]*self.uv_face_eye_mask + (torch.ones_like(uv_gt[:,:3,:,:])*(1-self.uv_face_eye_mask)*0.7)\n",
        "            \n",
        "        ## output\n",
        "        opdict = {\n",
        "            'vertices': verts,\n",
        "            'normals': ops['normals'],\n",
        "            'transformed_vertices': trans_verts,\n",
        "            'landmarks2d': landmarks2d,\n",
        "            'landmarks3d': landmarks3d,\n",
        "            'uv_detail_normals': uv_detail_normals,\n",
        "            'uv_texture_gt': uv_texture_gt,\n",
        "            'displacement_map': uv_z+self.fixed_uv_dis[None,None,:,:],\n",
        "        }\n",
        "        if self.cfg.model.use_tex:\n",
        "            opdict['albedo'] = albedo\n",
        "            opdict['uv_texture'] = uv_texture\n",
        "\n",
        "        visdict = {\n",
        "            'inputs': images, \n",
        "            'landmarks2d': util.tensor_vis_landmarks(images, landmarks2d, isScale=False),\n",
        "            'landmarks3d': util.tensor_vis_landmarks(images, landmarks3d, isScale=False),\n",
        "            'shape_images': shape_images,\n",
        "            'shape_detail_images': shape_detail_images,\n",
        "            'uv_texture': uv_texture,\n",
        "            'uv_texture_gt': uv_gt[:,:3,:,:]*self.uv_face_eye_mask,\n",
        "            'uv_gt': uv_gt,\n",
        "            'albedo': albedo\n",
        "        }\n",
        "        if self.cfg.model.use_tex:\n",
        "            visdict['rendered_images'] = ops['images']\n",
        "        return opdict, visdict\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def decode_modified(self, codedict, albedo):\n",
        "        images = codedict['images']\n",
        "        batch_size = images.shape[0]\n",
        "        \n",
        "        ## decode\n",
        "        verts, landmarks2d, landmarks3d = self.flame(shape_params=codedict['shape'], expression_params=codedict['exp'], pose_params=codedict['pose'])\n",
        "        uv_z = self.D_detail(torch.cat([codedict['pose'][:,3:], codedict['exp'], codedict['detail']], dim=1))\n",
        "       \n",
        "        ## projection\n",
        "        landmarks2d = util.batch_orth_proj(landmarks2d, codedict['cam'])[:,:,:2]; landmarks2d[:,:,1:] = -landmarks2d[:,:,1:]; landmarks2d = landmarks2d*self.image_size/2 + self.image_size/2\n",
        "        landmarks3d = util.batch_orth_proj(landmarks3d, codedict['cam']); landmarks3d[:,:,1:] = -landmarks3d[:,:,1:]; landmarks3d = landmarks3d*self.image_size/2 + self.image_size/2\n",
        "        trans_verts = util.batch_orth_proj(verts, codedict['cam']); trans_verts[:,:,1:] = -trans_verts[:,:,1:]\n",
        "        \n",
        "        ## rendering\n",
        "        ops = self.render(verts, trans_verts, albedo, codedict['light'])\n",
        "        uv_detail_normals = self.displacement2normal(uv_z, verts, ops['normals'])\n",
        "        uv_shading = self.render.add_SHlight(uv_detail_normals, codedict['light'])\n",
        "        uv_texture = albedo*uv_shading\n",
        "\n",
        "        landmarks3d_vis = self.visofp(ops['transformed_normals'])\n",
        "        landmarks3d = torch.cat([landmarks3d, landmarks3d_vis], dim=2)\n",
        "\n",
        "        ## render shape\n",
        "        shape_images = self.render.render_shape(verts, trans_verts, images=ops['albedo_images'], lights=codedict['light'])\n",
        "        # shape_images = self.render.render_shape(verts, trans_verts)\n",
        "\n",
        "        detail_normal_images = F.grid_sample(uv_detail_normals, ops['grid'], align_corners=False)*ops['alpha_images']\n",
        "        shape_detail_images = self.render.render_shape(verts, trans_verts, images=ops['albedo_images'], detail_normal_images=detail_normal_images, lights=codedict['light'])\n",
        "        # shape_detail_images = self.render.render_shape(verts, trans_verts, detail_normal_images=detail_normal_images)\n",
        "        \n",
        "        ## extract texture\n",
        "        ## TODO: current resolution 256x256, support higher resolution, and add visibility\n",
        "        uv_pverts = self.render.world2uv(trans_verts)\n",
        "        uv_gt = F.grid_sample(images, uv_pverts.permute(0,2,3,1)[:,:,:,:2], mode='bilinear')\n",
        "        if self.cfg.model.use_tex:\n",
        "            ## TODO: poisson blending should give better-looking results\n",
        "            uv_texture_gt = uv_gt[:,:3,:,:]*self.uv_face_eye_mask + (uv_texture[:,:3,:,:]*(1-self.uv_face_eye_mask)*0.7)\n",
        "        else:\n",
        "            uv_texture_gt = uv_gt[:,:3,:,:]*self.uv_face_eye_mask + (torch.ones_like(uv_gt[:,:3,:,:])*(1-self.uv_face_eye_mask)*0.7)\n",
        "            \n",
        "        ## output\n",
        "        opdict = {\n",
        "            'vertices': verts,\n",
        "            'normals': ops['normals'],\n",
        "            'transformed_vertices': trans_verts,\n",
        "            'landmarks2d': landmarks2d,\n",
        "            'landmarks3d': landmarks3d,\n",
        "            'uv_detail_normals': uv_detail_normals,\n",
        "            'uv_texture_gt': uv_texture_gt,\n",
        "            'displacement_map': uv_z+self.fixed_uv_dis[None,None,:,:],\n",
        "        }\n",
        "        if self.cfg.model.use_tex:\n",
        "            opdict['albedo'] = albedo\n",
        "            opdict['uv_texture'] = uv_texture\n",
        "\n",
        "        visdict = {\n",
        "            'inputs': images, \n",
        "            'landmarks2d': util.tensor_vis_landmarks(images, landmarks2d, isScale=False),\n",
        "            'landmarks3d': util.tensor_vis_landmarks(images, landmarks3d, isScale=False),\n",
        "            'shape_images': shape_images,\n",
        "            'shape_detail_images': shape_detail_images,\n",
        "            'uv_texture': uv_texture,\n",
        "            'uv_texture_gt': uv_gt[:,:3,:,:]*self.uv_face_eye_mask,\n",
        "            'uv_gt': uv_gt,\n",
        "            'albedo': albedo,\n",
        "            'albedo_image': ops['albedo_images'],\n",
        "            'detail_normal_images': detail_normal_images\n",
        "        }\n",
        "        if self.cfg.model.use_tex:\n",
        "            visdict['rendered_images'] = ops['images']\n",
        "        return opdict, visdict\n",
        "\n",
        "    def visualize(self, visdict, size=None):\n",
        "        grids = {}\n",
        "        if size is None:\n",
        "            size = self.image_size\n",
        "        for key in visdict:\n",
        "            grids[key] = torchvision.utils.make_grid(F.interpolate(visdict[key], [size, size])).detach().cpu()\n",
        "        grid = torch.cat(list(grids.values()), 2)\n",
        "        grid_image = (grid.numpy().transpose(1,2,0).copy()*255)[:,:,[2,1,0]]\n",
        "        grid_image = np.minimum(np.maximum(grid_image, 0), 255).astype(np.uint8)\n",
        "        return grid_image\n",
        "    \n",
        "    def save_obj(self, filename, opdict):\n",
        "        '''\n",
        "        vertices: [nv, 3], tensor\n",
        "        texture: [3, h, w], tensor\n",
        "        '''\n",
        "        i = 0\n",
        "        vertices = opdict['vertices'][i].cpu().numpy()\n",
        "        faces = self.render.faces[0].cpu().numpy()\n",
        "        texture = util.tensor2image(opdict['uv_texture_gt'][i])\n",
        "        uvcoords = self.render.raw_uvcoords[0].cpu().numpy()\n",
        "        uvfaces = self.render.uvfaces[0].cpu().numpy()\n",
        "        # save coarse mesh, with texture and normal map\n",
        "        normal_map = util.tensor2image(opdict['uv_detail_normals'][i]*0.5 + 0.5)\n",
        "        util.write_obj(filename, vertices, faces, \n",
        "                        texture=texture, \n",
        "                        uvcoords=uvcoords, \n",
        "                        uvfaces=uvfaces, \n",
        "                        normal_map=normal_map)\n",
        "        # upsample mesh, save detailed mesh\n",
        "        texture = texture[:,:,[2,1,0]]\n",
        "        normals = opdict['normals'][i].cpu().numpy()\n",
        "        displacement_map = opdict['displacement_map'][i].cpu().numpy().squeeze()\n",
        "        dense_vertices, dense_colors, dense_faces = util.upsample_mesh(vertices, normals, faces, displacement_map, texture, self.dense_template)\n",
        "        util.write_obj(filename.replace('.obj', '_detail.obj'), \n",
        "                        dense_vertices, \n",
        "                        dense_faces,\n",
        "                        colors = dense_colors,\n",
        "                        inverse_face_order=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DECA expression, pose"
      ],
      "metadata": {
        "id": "iYSyck_-cmFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'savefolder': '/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/FaceForensics/videos/original_sequences/youtube/raw/results',\n",
        "    'inputpath': '/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/FaceForensics/videos/original_sequences/youtube/raw/videos', # '/content/bupt_balanced_1440' #'TestSamples/teaser',\n",
        "    'exp_path': 'TestSamples/exp',\n",
        "    'device': 'cuda',\n",
        "    'iscrop': True, \n",
        "    'detector': 'fan'\n",
        "}"
      ],
      "metadata": {
        "id": "CG7QxQs3dMqU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'num_generated_frames': 2100,\n",
        "    'upper_range': 1.1,\n",
        "    'lower_range': 0.9,\n",
        "    'generated_video_path': '/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/FaceForensics/videos/original_sequences/youtube/raw/results',\n",
        "    'batch_size': 30\n",
        "}\n",
        "\n",
        "Path(params['generated_video_path']).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "sjKvqdfczt3X"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "savefolder = args['savefolder']\n",
        "device = args['device']\n",
        "os.makedirs(savefolder, exist_ok=True)\n",
        "\n",
        "# DECA\n",
        "deca_cfg.model.use_tex = True\n",
        "deca = DECA(config = deca_cfg, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229,
          "referenced_widgets": [
            "fc1d042b313a47f2829cfcc4452016ab",
            "3f3d2ab097ad45169b9a657d5053608b",
            "b70e9924af0b4d1aa268e9c6ec316a04",
            "520314d11d34419d9ef1bb3dfe1b132d",
            "1bdff5b427864d579963d74ded918392",
            "fccaa1a3fde14b5994260532ef1936f3",
            "04c157227b854974ad477a85f57b8613",
            "5d2485d70b754456a81f813abaa3dff3",
            "640f500683c547b98a416e3ed8a9c5de",
            "9730a8b7a3bd42b19871f31e57af571b",
            "9f9f1b9d4a9b4987992e315279904b01"
          ]
        },
        "id": "ZGaHQboEd476",
        "outputId": "51994a93-58d3-4571-cec8-d57de81b9c70"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc1d042b313a47f2829cfcc4452016ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc.weight  not available in reconstructed resnet\n",
            "fc.bias  not available in reconstructed resnet\n",
            "fc.weight  not available in reconstructed resnet\n",
            "fc.bias  not available in reconstructed resnet\n",
            "creating the FLAME Decoder\n",
            "trained model found. load /content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/DECA/DECA/data/deca_model.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch3d/io/obj_io.py:534: UserWarning: Mtl file does not exist: /content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/DECA/DECA/data/template.mtl\n",
            "  warnings.warn(f\"Mtl file does not exist: {f}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_aap =  nn.AdaptiveAvgPool2d((80, 80)) #use adaptive avg pooling to downsample image to 80x80\n",
        "# m_upsample =  nn.AdaptiveAvgPool2d((256, 256))\n",
        "with torch.no_grad():\n",
        "\ttestdata = datasets_video.TestData_Videos(args['inputpath'], iscrop=args['iscrop'], face_detector=args['detector'])\n",
        "\tprint(len(testdata)) \n",
        "\tfor i in range(630,len(testdata)): \n",
        "\t\t# load image\n",
        "\t\tprint('processing {} video'.format(i))\n",
        "\t\t# name = testdata[i]['imagename']\n",
        "\t\t# frames = testdata[i]['image']\n",
        "\t\tframes,name = testdata[i]\n",
        "\t\tposes = []\n",
        "\t\texpressions = []\n",
        "\t\tfor frame in frames:\n",
        "\t\t\timages = frame.to(device)[None,...]\n",
        "\t\t\timages = images.repeat(params['batch_size'], 1, 1, 1)\n",
        "\t\t\tcodedict = deca.encode(images)\n",
        "\t\t\topdict, visdict = deca.decode(codedict) #tensor\n",
        "\t\t\t# target_exp = codedict['exp'].cpu()[0].permute(1, 2, 0).numpy()\n",
        "\t\t\ttarget_exp = codedict['exp'].cpu().numpy()\n",
        "\t\t\ttarget_pose = codedict['pose'].cpu().numpy()\n",
        "\t\t\t# print(\"exp shape = \", target_exp.shape, \" pose shape = \",target_pose.shape)\n",
        "\t\t\timages = images.cpu()\n",
        "\t\t\tposes.append(target_pose)\n",
        "\t\t\texpressions.append(target_exp)\n",
        "\n",
        "\t\tnew_h5_name = name + '_pose_exp_ytb.h5'\n",
        "\t\thf = h5py.File(os.path.join(params['generated_video_path'], new_h5_name), 'w')\n",
        "\t\thf.create_dataset('pose', data=np.array(poses))\n",
        "\t\thf.create_dataset('exp', data=np.array(expressions))\n",
        "\t\thf.close()\n",
        "\t\tprint(new_h5_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b5bf871275b4630912e878daebfb014",
            "ce17af1976154d19a4b1de384cdb5c56",
            "4848d10d8d234807a4dfcb04e502bba8",
            "aaed1b60f14b4734a690890e1a81a906",
            "16ade944add445a39fbafe7ff2fd22ac",
            "1d5d275676e64d3b855f02d85e88e8b5",
            "54da5aea255a435891b8d2ee0eb7ff14",
            "d8f1730ca9414cbdb23f1588bed7a5a7",
            "b5a384a9c8db4ef49ed00b1a42c706bd",
            "b0fd5a8cd6cc4ef09d72ab14d3dd078c",
            "97a990053c0e48b2b0dc01d5546f5543",
            "6d365dbc62654093addbd3ca10385771",
            "cf9798c3115a4bd782017cc46d01c300",
            "cbe75b07bfda4df2b4d9dba16acec584",
            "9aea940a618247eaabb0b8d332b352fe",
            "b269b5e9b4f04ca0a7c47c267d0c2c52",
            "b134e20a9eeb496aa341742b8d093492",
            "15d6eeca86bb46bb9a18581ce0fa72f9",
            "5e441199ef3e4ef5b80ffe9345af16c0",
            "c9bba93ca28f45d7b1c5079049b8d79b",
            "d460ae1cc2014c52b0ebb406524133f3",
            "8e4d1c594af7432ab2f926a6e2a6da0a"
          ]
        },
        "id": "gwLIEWfv4bCO",
        "outputId": "b67f1c8d-806a-42c9-bfb9-6b7e6879487a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1000 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/85.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b5bf871275b4630912e878daebfb014"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/2DFAN4_1.6-c827573f02.zip\" to /root/.cache/torch/hub/checkpoints/2DFAN4_1.6-c827573f02.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/91.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d365dbc62654093addbd3ca10385771"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "processing 630 video\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/gdrive/.shortcut-targets-by-id/1Kv4V2PfcDb3WIGdtBo48x6lRiYbsR3GM/Biofacenet_n/DECA/DECA/decalib/utils/util.py:210: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
            "  vertices_faces = vertices.reshape((bs * nv, 3))[faces.long()]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "630_pose_exp_ytb.h5\n",
            "processing 631 video\n",
            "631_pose_exp_ytb.h5\n",
            "processing 632 video\n",
            "632_pose_exp_ytb.h5\n",
            "processing 633 video\n",
            "633_pose_exp_ytb.h5\n",
            "processing 634 video\n",
            "634_pose_exp_ytb.h5\n",
            "processing 635 video\n",
            "635_pose_exp_ytb.h5\n",
            "processing 636 video\n",
            "636_pose_exp_ytb.h5\n",
            "processing 637 video\n",
            "637_pose_exp_ytb.h5\n",
            "processing 638 video\n",
            "638_pose_exp_ytb.h5\n",
            "processing 639 video\n",
            "639_pose_exp_ytb.h5\n",
            "processing 640 video\n",
            "640_pose_exp_ytb.h5\n",
            "processing 641 video\n",
            "641_pose_exp_ytb.h5\n",
            "processing 642 video\n",
            "642_pose_exp_ytb.h5\n",
            "processing 643 video\n",
            "643_pose_exp_ytb.h5\n",
            "processing 644 video\n",
            "644_pose_exp_ytb.h5\n",
            "processing 645 video\n",
            "645_pose_exp_ytb.h5\n",
            "processing 646 video\n",
            "646_pose_exp_ytb.h5\n",
            "processing 647 video\n",
            "647_pose_exp_ytb.h5\n",
            "processing 648 video\n",
            "648_pose_exp_ytb.h5\n",
            "processing 649 video\n",
            "649_pose_exp_ytb.h5\n",
            "processing 650 video\n",
            "650_pose_exp_ytb.h5\n",
            "processing 651 video\n",
            "651_pose_exp_ytb.h5\n",
            "processing 652 video\n",
            "652_pose_exp_ytb.h5\n",
            "processing 653 video\n",
            "653_pose_exp_ytb.h5\n",
            "processing 654 video\n",
            "654_pose_exp_ytb.h5\n",
            "processing 655 video\n",
            "655_pose_exp_ytb.h5\n",
            "processing 656 video\n",
            "656_pose_exp_ytb.h5\n",
            "processing 657 video\n",
            "657_pose_exp_ytb.h5\n",
            "processing 658 video\n",
            "658_pose_exp_ytb.h5\n",
            "processing 659 video\n",
            "659_pose_exp_ytb.h5\n",
            "processing 660 video\n",
            "660_pose_exp_ytb.h5\n",
            "processing 661 video\n",
            "661_pose_exp_ytb.h5\n",
            "processing 662 video\n",
            "662_pose_exp_ytb.h5\n",
            "processing 663 video\n",
            "663_pose_exp_ytb.h5\n",
            "processing 664 video\n",
            "664_pose_exp_ytb.h5\n",
            "processing 665 video\n",
            "665_pose_exp_ytb.h5\n",
            "processing 666 video\n",
            "666_pose_exp_ytb.h5\n",
            "processing 667 video\n",
            "667_pose_exp_ytb.h5\n",
            "processing 668 video\n",
            "668_pose_exp_ytb.h5\n",
            "processing 669 video\n",
            "669_pose_exp_ytb.h5\n",
            "processing 670 video\n",
            "670_pose_exp_ytb.h5\n",
            "processing 671 video\n",
            "671_pose_exp_ytb.h5\n",
            "processing 672 video\n",
            "672_pose_exp_ytb.h5\n",
            "processing 673 video\n",
            "673_pose_exp_ytb.h5\n",
            "processing 674 video\n",
            "674_pose_exp_ytb.h5\n",
            "processing 675 video\n",
            "675_pose_exp_ytb.h5\n",
            "processing 676 video\n",
            "676_pose_exp_ytb.h5\n",
            "processing 677 video\n",
            "677_pose_exp_ytb.h5\n",
            "processing 678 video\n",
            "678_pose_exp_ytb.h5\n",
            "processing 679 video\n",
            "679_pose_exp_ytb.h5\n",
            "processing 680 video\n",
            "680_pose_exp_ytb.h5\n",
            "processing 681 video\n",
            "681_pose_exp_ytb.h5\n",
            "processing 682 video\n",
            "682_pose_exp_ytb.h5\n",
            "processing 683 video\n",
            "683_pose_exp_ytb.h5\n",
            "processing 684 video\n",
            "684_pose_exp_ytb.h5\n",
            "processing 685 video\n",
            "685_pose_exp_ytb.h5\n",
            "processing 686 video\n",
            "686_pose_exp_ytb.h5\n",
            "processing 687 video\n",
            "687_pose_exp_ytb.h5\n",
            "processing 688 video\n",
            "688_pose_exp_ytb.h5\n",
            "processing 689 video\n",
            "689_pose_exp_ytb.h5\n",
            "processing 690 video\n",
            "690_pose_exp_ytb.h5\n",
            "processing 691 video\n",
            "691_pose_exp_ytb.h5\n",
            "processing 692 video\n",
            "692_pose_exp_ytb.h5\n",
            "processing 693 video\n",
            "693_pose_exp_ytb.h5\n",
            "processing 694 video\n",
            "694_pose_exp_ytb.h5\n",
            "processing 695 video\n",
            "695_pose_exp_ytb.h5\n",
            "processing 696 video\n",
            "696_pose_exp_ytb.h5\n",
            "processing 697 video\n",
            "697_pose_exp_ytb.h5\n",
            "processing 698 video\n",
            "698_pose_exp_ytb.h5\n",
            "processing 699 video\n",
            "699_pose_exp_ytb.h5\n",
            "processing 700 video\n",
            "700_pose_exp_ytb.h5\n",
            "processing 701 video\n",
            "701_pose_exp_ytb.h5\n",
            "processing 702 video\n",
            "702_pose_exp_ytb.h5\n",
            "processing 703 video\n",
            "703_pose_exp_ytb.h5\n",
            "processing 704 video\n",
            "704_pose_exp_ytb.h5\n",
            "processing 705 video\n",
            "705_pose_exp_ytb.h5\n",
            "processing 706 video\n",
            "706_pose_exp_ytb.h5\n",
            "processing 707 video\n",
            "707_pose_exp_ytb.h5\n",
            "processing 708 video\n",
            "708_pose_exp_ytb.h5\n",
            "processing 709 video\n",
            "709_pose_exp_ytb.h5\n",
            "processing 710 video\n",
            "710_pose_exp_ytb.h5\n",
            "processing 711 video\n",
            "711_pose_exp_ytb.h5\n",
            "processing 712 video\n",
            "712_pose_exp_ytb.h5\n",
            "processing 713 video\n",
            "713_pose_exp_ytb.h5\n",
            "processing 714 video\n",
            "714_pose_exp_ytb.h5\n",
            "processing 715 video\n",
            "715_pose_exp_ytb.h5\n",
            "processing 716 video\n",
            "716_pose_exp_ytb.h5\n",
            "processing 717 video\n",
            "717_pose_exp_ytb.h5\n",
            "processing 718 video\n",
            "718_pose_exp_ytb.h5\n",
            "processing 719 video\n",
            "719_pose_exp_ytb.h5\n",
            "processing 720 video\n",
            "720_pose_exp_ytb.h5\n",
            "processing 721 video\n",
            "721_pose_exp_ytb.h5\n",
            "processing 722 video\n",
            "722_pose_exp_ytb.h5\n",
            "processing 723 video\n",
            "723_pose_exp_ytb.h5\n",
            "processing 724 video\n",
            "724_pose_exp_ytb.h5\n",
            "processing 725 video\n",
            "725_pose_exp_ytb.h5\n",
            "processing 726 video\n",
            "726_pose_exp_ytb.h5\n",
            "processing 727 video\n",
            "727_pose_exp_ytb.h5\n",
            "processing 728 video\n",
            "728_pose_exp_ytb.h5\n",
            "processing 729 video\n",
            "729_pose_exp_ytb.h5\n",
            "processing 730 video\n",
            "730_pose_exp_ytb.h5\n",
            "processing 731 video\n",
            "731_pose_exp_ytb.h5\n",
            "processing 732 video\n",
            "732_pose_exp_ytb.h5\n",
            "processing 733 video\n",
            "733_pose_exp_ytb.h5\n",
            "processing 734 video\n",
            "734_pose_exp_ytb.h5\n",
            "processing 735 video\n",
            "735_pose_exp_ytb.h5\n",
            "processing 736 video\n",
            "736_pose_exp_ytb.h5\n",
            "processing 737 video\n",
            "737_pose_exp_ytb.h5\n",
            "processing 738 video\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-c1WeaNQFWG"
      },
      "source": [
        "# Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUUFjXu76lMa"
      },
      "outputs": [],
      "source": [
        "torch.max(reconstructed_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l1yn8HXeCk6"
      },
      "outputs": [],
      "source": [
        "np.array(visdict_list).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQwWYB_Zlwpw"
      },
      "outputs": [],
      "source": [
        "data=torch.from_numpy(np.array(visdict_list)).float()\n",
        "torch.save(data,'./../celebAHQ_deca_albedo_2000_256.bin')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "ppb_expr_pose_deca_celeba_Mar27_Diplav.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fc1d042b313a47f2829cfcc4452016ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f3d2ab097ad45169b9a657d5053608b",
              "IPY_MODEL_b70e9924af0b4d1aa268e9c6ec316a04",
              "IPY_MODEL_520314d11d34419d9ef1bb3dfe1b132d"
            ],
            "layout": "IPY_MODEL_1bdff5b427864d579963d74ded918392"
          }
        },
        "3f3d2ab097ad45169b9a657d5053608b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fccaa1a3fde14b5994260532ef1936f3",
            "placeholder": "​",
            "style": "IPY_MODEL_04c157227b854974ad477a85f57b8613",
            "value": "100%"
          }
        },
        "b70e9924af0b4d1aa268e9c6ec316a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d2485d70b754456a81f813abaa3dff3",
            "max": 102502400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_640f500683c547b98a416e3ed8a9c5de",
            "value": 102502400
          }
        },
        "520314d11d34419d9ef1bb3dfe1b132d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9730a8b7a3bd42b19871f31e57af571b",
            "placeholder": "​",
            "style": "IPY_MODEL_9f9f1b9d4a9b4987992e315279904b01",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 138MB/s]"
          }
        },
        "1bdff5b427864d579963d74ded918392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccaa1a3fde14b5994260532ef1936f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c157227b854974ad477a85f57b8613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d2485d70b754456a81f813abaa3dff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640f500683c547b98a416e3ed8a9c5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9730a8b7a3bd42b19871f31e57af571b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f9f1b9d4a9b4987992e315279904b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b5bf871275b4630912e878daebfb014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce17af1976154d19a4b1de384cdb5c56",
              "IPY_MODEL_4848d10d8d234807a4dfcb04e502bba8",
              "IPY_MODEL_aaed1b60f14b4734a690890e1a81a906"
            ],
            "layout": "IPY_MODEL_16ade944add445a39fbafe7ff2fd22ac"
          }
        },
        "ce17af1976154d19a4b1de384cdb5c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d5d275676e64d3b855f02d85e88e8b5",
            "placeholder": "​",
            "style": "IPY_MODEL_54da5aea255a435891b8d2ee0eb7ff14",
            "value": "100%"
          }
        },
        "4848d10d8d234807a4dfcb04e502bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f1730ca9414cbdb23f1588bed7a5a7",
            "max": 89843225,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5a384a9c8db4ef49ed00b1a42c706bd",
            "value": 89843225
          }
        },
        "aaed1b60f14b4734a690890e1a81a906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0fd5a8cd6cc4ef09d72ab14d3dd078c",
            "placeholder": "​",
            "style": "IPY_MODEL_97a990053c0e48b2b0dc01d5546f5543",
            "value": " 85.7M/85.7M [00:06&lt;00:00, 17.0MB/s]"
          }
        },
        "16ade944add445a39fbafe7ff2fd22ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5d275676e64d3b855f02d85e88e8b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54da5aea255a435891b8d2ee0eb7ff14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8f1730ca9414cbdb23f1588bed7a5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5a384a9c8db4ef49ed00b1a42c706bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0fd5a8cd6cc4ef09d72ab14d3dd078c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a990053c0e48b2b0dc01d5546f5543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d365dbc62654093addbd3ca10385771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf9798c3115a4bd782017cc46d01c300",
              "IPY_MODEL_cbe75b07bfda4df2b4d9dba16acec584",
              "IPY_MODEL_9aea940a618247eaabb0b8d332b352fe"
            ],
            "layout": "IPY_MODEL_b269b5e9b4f04ca0a7c47c267d0c2c52"
          }
        },
        "cf9798c3115a4bd782017cc46d01c300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b134e20a9eeb496aa341742b8d093492",
            "placeholder": "​",
            "style": "IPY_MODEL_15d6eeca86bb46bb9a18581ce0fa72f9",
            "value": "100%"
          }
        },
        "cbe75b07bfda4df2b4d9dba16acec584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e441199ef3e4ef5b80ffe9345af16c0",
            "max": 96404224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9bba93ca28f45d7b1c5079049b8d79b",
            "value": 96404224
          }
        },
        "9aea940a618247eaabb0b8d332b352fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d460ae1cc2014c52b0ebb406524133f3",
            "placeholder": "​",
            "style": "IPY_MODEL_8e4d1c594af7432ab2f926a6e2a6da0a",
            "value": " 91.9M/91.9M [00:06&lt;00:00, 16.5MB/s]"
          }
        },
        "b269b5e9b4f04ca0a7c47c267d0c2c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b134e20a9eeb496aa341742b8d093492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d6eeca86bb46bb9a18581ce0fa72f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e441199ef3e4ef5b80ffe9345af16c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9bba93ca28f45d7b1c5079049b8d79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d460ae1cc2014c52b0ebb406524133f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e4d1c594af7432ab2f926a6e2a6da0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}